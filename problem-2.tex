%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is how you write code:
%
% \begin{minted}{matlab}
% foo = [2 1 0;1 4 3;2 4.5 6];
% \end{minted}
%

% This is how you import code:
% 
% \inputminted[linenos]{matlab}{foo_bar.m}
%
 
% Most figures are imported this way:
%
% \begin{figure}
% \includegraphics[width=\textwidth]{foo_figure}
% \caption{This is a caption}
% \end{figure}

% This is a matrix:
%
% \begin{equation}
% H =
%  \left[
%  \begin{matrix}
%    1 & 2 &  3 &  4 \\ 
%    5 & 6 &  7 &  8 \\ 
%    0 & 9 & 10 & 11 \\ 
%    0 & 0 & 12 &  0
%  \end{matrix} 
% \right]
%\end{equation}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% For better looking tables
\newcommand{\head}[1]{\textnormal{\textbf{#1}}}

\documentclass[00-main.tex]{subfiles}
\begin{document}


\section*{Problem Two}

In the following $X_n$ is the number of individuals in the $n$'th generation,
 $X_0$ is the initial population, $\mu = E[$\textit{children per individual}$]$, $p_j = P\{$\textit{an individual has }$j$\textit{ offspring}$\}$. The distributions that are analyzed are listed in \cref{p-values}
 
\begin{table}[!htbp]
\centering
\begin{tabular}{ccccc}
  \hline
  \noalign{\smallskip}
  \head{ } & \head{$p_0$} & \head{$p_1$} & \head{$p_2$} & \head{$p_3$}\\
  \hline
  \noalign{\smallskip}
  \textbf{I} & 0.6 & 0.05 & 0.15 & 0.2 \\
  \textbf{II} & 0.25 & 0.60 & 0.10 & 0.05 \\
  \hline
\end{tabular}
\caption{The probability distributions given in Problem Two.}
\label{p-values}
\end{table}

Chapter 4.7 in \cite{ross} presents some results that are used in this problem. Below is some properties of branching processes discussed.

Generally, the mean number, and the variance, off offspring of a single individual is

\begin{equation}
\label{meanvar}
\mu = \sum_{j=0}^{\infty} jP_j \quad \quad \text{and} \quad \quad \sigma^2 = \sum_{j=0}^{\infty} (j-\mu)^2P_j
\end{equation}

respectively.

For both our distributions $\mu = 0.95$, and since $\mu < 1$ the population will eventually die out. Defining $Z_i$ to be the number of offspring of the $i$'th individual for the $(n-1)$st generation, one can find 

\begin{equation}
X_n = \sum_{i=1}^{X_{n-1}} Z_i
\end{equation}

in the edge case where $X_0=1$. One can then obtain

\begin{equation}
E[X_n] = E[E[X_n | X_{n-1}]] = E\left[ E\left[ \sum_{i=1}^{X_{n-1}} Z_i | X_{i-1} \right] \right] = E[X_{n-1}] \mu 
\end{equation}

which leads to the result

\begin{equation}
E[X_1] = \mu, \quad E[X_2] = \mu E[X_1] = \mu^2, \quad \cdots, \quad E[X_n] = \mu^n.
\end{equation}

It can then be shown that the variance is

\begin{align}
\label{variance}
  Var(X_n) = \left\{ 
  \begin{array}{l l l}
     \sigma^2 \mu^{n-1} \cdot \frac{1-\mu^n}{1-\mu}, \quad &\mu \neq 1\\
     n \sigma^2, \quad  &\mu = 1 \\
  \end{array} \right.
\end{align}

When doing simulations, the estimated mean value and standard deviation is given by

\begin{equation}
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i, \qquad S^2 = \frac{1}{n-1}\sum_{i=1}^{n} X_i - \bar{X},
\end{equation}

respectively. 

\subsection*{a.}

The mean and standard deviation is found analytically from \cref{meanvar} and \cref{variance}, and is presented in \cref{anatable}.

\begin{table}[!htbp]
\centering
\begin{tabular}{ccccc}
  \hline
  \noalign{\smallskip}
  $n$ & $E[X_n]$ & $SD_I[X_n]$ & $SD_{II}[X_n]$   \\
  \hline
  \noalign{\smallskip}
  10   & 0.5987 & 2.7977 & 2.7692 &    \\
  100  & 0.0059 & 0.4379 & 0.0678 &    \\
  1000 & 5.2912e-23 & 4.1529e-11 & 2.4697e-11 &    \\
  \hline
\end{tabular}
\caption{Analytical values of the mean $E[X_n]$ and the standard deviation, SD ($=Var^{\frac{1}{2}}[X_n]$) for distribution I and II.}
\label{anatable}
\end{table}


The branching process was simulated one million times for each of the probability distributions. The values in \cref{simtable} was computed by running

\begin{minted}{matlab}
branchtrials(1000000, 1, [0.60 0.05 0.15 0.20]);
branchtrials(1000000, 1, [0.25 0.60 0.10 0.05]);
\end{minted}


\begin{table}[!htbp]
\centering
\begin{tabular}{ccccc}
  \hline
  \noalign{\smallskip}
  $n$ & $E_I[X_n]$ &$E_{II}[X_n]$ & $SD_I[X_n]$ & $SD_{II}[X_n]$   \\
  \hline
  \noalign{\smallskip}
  10   & 0.6007 & 0.5989 & 2.8099 & 1.6645     \\
  100  & 0.0060 & 0.0060 & 0.4346 & 0.2582     \\
  1000 & 0 & 0 & 0 & 0    \\
  \hline
\end{tabular}
\caption{Simulated values of the mean $E[X_n]$ and the standard deviation, SD ($=Var^{\frac{1}{2}}[X_n]$) for distribution I and II.}
\label{simtable}
\end{table}

The simulated values is indeed very close to the ones found analytically for both distributions. Given that the \textsc{matlab} rand()-function is uniform, the simulated values would probably become even more accurate if the number of simulations is increased. No simulation ever reached $n=1000$, but this is only natural considering the low probability for that to happen. 

(i), (ii) and (iii) are presented in 

\begin{table}[!htbp]
\centering
\begin{tabular}{ccccc}
  \hline
  \noalign{\smallskip}
   & \multicolumn{2}{c|}{Distribution I} & \multicolumn{2}{c}{Distribution II} \\
  \head{Case} & $E[\cdot]$ &$SD[\cdot]$ & $ E[\cdot]$ &$SD[\cdot]$   \\
  \hline
  \noalign{\smallskip}
  (i)   & 0.6007 & 0.5989 & 2.8099 & 1.6645     \\
  (ii)  & 0.0060 & 0.0060 & 0.4346 & 0.2582     \\
  (iii)  & 0.0060 & 0.0060 & 0.4346 & 0.2582     \\
  \hline
\end{tabular}
\caption{Simulated values of the mean $E[X_n]$ and the standard deviation, SD ($=Var^{\frac{1}{2}}[X_n]$) for distribution I and II.}
\label{simtable2}
\end{table}

\textbf{(i) Number of generations until the population dies}





















\end{document}